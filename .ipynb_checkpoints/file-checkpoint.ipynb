{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 123] 파일 이름, 디렉터리 이름 또는 볼륨 레이블 구문이 잘못되었습니다: 'D:\\\\data\\\\사람동작 영상\\x07nnotation\\x02D'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m path_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m사람동작 영상\u001b[39m\u001b[38;5;130;01m\\a\u001b[39;00m\u001b[38;5;124mnnotation\u001b[39m\u001b[38;5;130;01m\\2\u001b[39;00m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m file_list1 \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 123] 파일 이름, 디렉터리 이름 또는 볼륨 레이블 구문이 잘못되었습니다: 'D:\\\\data\\\\사람동작 영상\\x07nnotation\\x02D'"
     ]
    }
   ],
   "source": [
    "path_dir = 'D:\\data\\사람동작 영상\\annotation\\2D\\'\n",
    "file_list1 = os.listdir(path_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 348/348 [06:48<00:00,  1.18s/it]\n"
     ]
    }
   ],
   "source": [
    "false_data = list()\n",
    "true_data = list()\n",
    "\n",
    "true_name = list()\n",
    "\n",
    "for file_name1 in tqdm(file_list1):\n",
    "    #print(file_name1)\n",
    "    file_path = path_dir + '/' + file_name1\n",
    "\n",
    "    file_list2 = os.listdir(file_path)\n",
    "\n",
    "    if file_name1[0] == '6': # 쓰러짐 영상\n",
    "        for file_name2 in file_list2:\n",
    "            read_file_path = file_path + '/' + file_name2\n",
    "            true_name.append(file_name2)\n",
    "\n",
    "            with open(read_file_path, 'r') as f:\n",
    "                json_data = json.load(f)\n",
    "                #print(json_data.keys())\n",
    "                tmpList = list()\n",
    "\n",
    "                for data in json_data['annotations']:\n",
    "                    tmpList.append(data['keypoints'])\n",
    "\n",
    "                true_data.append(tmpList)\n",
    "\n",
    "    else: # 기타 영상\n",
    "        for file_name2 in file_list2:\n",
    "            read_file_path = file_path + '/' + file_name2\n",
    "\n",
    "\n",
    "            with open(read_file_path, 'r') as f:\n",
    "                json_data = json.load(f)\n",
    "                #print(json_data.keys())\n",
    "                tmpList = list()\n",
    "                for data in json_data['annotations']:\n",
    "                    tmpList.append(data['keypoints'])\n",
    "\n",
    "                false_data.append(tmpList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_list = list()\n",
    "for data in true_data:\n",
    "    num_list.append(len(data))\n",
    "\n",
    "print(np.mean(num_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[930.0, 627.0, 2.0, 927.0, 559.0, 2.0, 933.0, 475.0, 2.0, 981.0, 473.0, 2.0, 970.0, 560.0, 2.0, 960.0, 632.0, 2.0, 954.0, 473.0, 2.0, 952.0, 397.0, 2.0, 951.0, 346.0, 2.0, 949.0, 288.0, 2.0, 943.0, 354.0, 2.0, 933.0, 382.0, 2.0, 921.0, 350.0, 2.0, 979.0, 361.0, 2.0, 1019.0, 393.0, 2.0, 1016.0, 357.0, 2.0], [930.0, 627.0, 2.0, 927.0, 559.0, 2.0, 933.0, 475.0, 2.0, 981.0, 473.0, 2.0, 970.0, 560.0, 2.0, 960.0, 632.0, 2.0, 954.0, 473.0, 2.0, 952.0, 397.0, 2.0, 951.0, 346.0, 2.0, 949.0, 288.0, 2.0, 943.0, 354.0, 2.0, 933.0, 382.0, 2.0, 921.0, 350.0, 2.0, 979.0, 361.0, 2.0, 1019.0, 393.0, 2.0, 1016.0, 357.0, 2.0], [922.0, 632.0, 2.0, 929.0, 552.0, 2.0, 933.0, 462.0, 2.0, 972.0, 462.0, 2.0, 969.0, 552.0, 2.0, 965.0, 628.0, 2.0, 954.0, 462.0, 2.0, 958.0, 391.0, 2.0, 961.0, 343.0, 2.0, 972.0, 281.0, 2.0, 936.0, 418.0, 2.0, 904.0, 411.0, 2.0, 926.0, 353.0, 2.0, 990.0, 364.0, 2.0, 998.0, 418.0, 2.0, 1026.0, 429.0, 2.0], [931.0, 631.0, 2.0, 960.0, 564.0, 2.0, 916.0, 520.0, 2.0, 969.0, 523.0, 1.0, 1010.0, 570.0, 2.0, 966.0, 628.0, 2.0, 942.0, 520.0, 1.0, 967.0, 464.0, 2.0, 983.0, 427.0, 2.0, 1010.0, 363.0, 2.0, 966.0, 535.0, 2.0, 940.0, 494.0, 2.0, 948.0, 429.0, 2.0, 1015.0, 438.0, 2.0, 1033.0, 494.0, 2.0, 1045.0, 541.0, 2.0], [939.0, 635.0, 2.0, 983.0, 611.0, 2.0, 916.0, 593.0, 2.0, 949.0, 593.0, 1.0, 1036.0, 606.0, 2.0, 989.0, 632.0, 2.0, 936.0, 593.0, 1.0, 976.0, 551.0, 1.0, 1003.0, 523.0, 2.0, 1045.0, 465.0, 2.0, 1027.0, 628.0, 2.0, 989.0, 587.0, 2.0, 980.0, 526.0, 2.0, 1036.0, 529.0, 2.0, 1068.0, 584.0, 2.0, 1085.0, 631.0, 2.0], [944.0, 627.0, 2.0, 1004.0, 629.0, 2.0, 954.0, 581.0, 2.0, 946.0, 573.0, 1.0, 1050.0, 620.0, 2.0, 975.0, 627.0, 1.0, 942.0, 570.0, 1.0, 1012.0, 545.0, 1.0, 1058.0, 528.0, 2.0, 1128.0, 499.0, 2.0, 1039.0, 640.0, 2.0, 1018.0, 593.0, 2.0, 1036.0, 532.0, 2.0, 1090.0, 529.0, 1.0, 1096.0, 587.0, 2.0, 1117.0, 641.0, 2.0], [907.0, 625.0, 2.0, 948.0, 641.0, 2.0, 992.0, 569.0, 2.0, 1024.0, 597.0, 1.0, 1006.0, 627.0, 1.0, 940.0, 621.0, 1.0, 1004.0, 583.0, 1.0, 1065.0, 559.0, 1.0, 1106.0, 543.0, 2.0, 1149.0, 510.0, 2.0, 1043.0, 648.0, 2.0, 1025.0, 605.0, 2.0, 1069.0, 529.0, 2.0, 1132.0, 559.0, 2.0, 1125.0, 605.0, 2.0, 1121.0, 641.0, 2.0], [872.0, 616.0, 2.0, 947.0, 641.0, 2.0, 1009.0, 622.0, 2.0, 1011.0, 623.0, 1.0, 954.0, 630.0, 1.0, 893.0, 612.0, 1.0, 1007.0, 623.0, 1.0, 1075.0, 600.0, 1.0, 1121.0, 584.0, 2.0, 1167.0, 551.0, 2.0, 1043.0, 652.0, 2.0, 1022.0, 622.0, 2.0, 1085.0, 573.0, 2.0, 1136.0, 605.0, 2.0, 1106.0, 627.0, 1.0, 1122.0, 652.0, 2.0], [864.0, 616.0, 2.0, 935.0, 640.0, 2.0, 1004.0, 619.0, 2.0, 1003.0, 611.0, 1.0, 956.0, 630.0, 1.0, 918.0, 602.0, 2.0, 1001.0, 615.0, 1.0, 1084.0, 624.0, 1.0, 1139.0, 630.0, 2.0, 1205.0, 633.0, 2.0, 1019.0, 653.0, 2.0, 1037.0, 590.0, 2.0, 1129.0, 623.0, 2.0, 1117.0, 633.0, 1.0, 1121.0, 598.0, 2.0, 1122.0, 624.0, 1.0], [870.0, 626.0, 2.0, 941.0, 636.0, 2.0, 1012.0, 626.0, 2.0, 1012.0, 621.0, 1.0, 946.0, 631.0, 1.0, 904.0, 614.0, 2.0, 1011.0, 617.0, 1.0, 1087.0, 628.0, 1.0, 1138.0, 636.0, 2.0, 1209.0, 646.0, 2.0, 980.0, 648.0, 2.0, 1043.0, 651.0, 2.0, 1095.0, 646.0, 2.0, 1128.0, 626.0, 1.0, 1112.0, 622.0, 1.0, 1071.0, 620.0, 1.0], [870.0, 626.0, 2.0, 941.0, 636.0, 2.0, 1012.0, 626.0, 2.0, 1012.0, 621.0, 1.0, 946.0, 631.0, 1.0, 904.0, 614.0, 2.0, 1011.0, 617.0, 1.0, 1087.0, 628.0, 1.0, 1138.0, 636.0, 2.0, 1209.0, 646.0, 2.0, 980.0, 648.0, 2.0, 1043.0, 651.0, 2.0, 1095.0, 646.0, 2.0, 1128.0, 626.0, 1.0, 1112.0, 622.0, 1.0, 1071.0, 620.0, 1.0], [870.0, 626.0, 2.0, 941.0, 636.0, 2.0, 1012.0, 626.0, 2.0, 1012.0, 621.0, 1.0, 946.0, 631.0, 1.0, 904.0, 614.0, 2.0, 1011.0, 617.0, 1.0, 1087.0, 628.0, 1.0, 1138.0, 636.0, 2.0, 1209.0, 646.0, 2.0, 980.0, 648.0, 2.0, 1043.0, 651.0, 2.0, 1095.0, 646.0, 2.0, 1128.0, 626.0, 1.0, 1112.0, 622.0, 1.0, 1071.0, 620.0, 1.0], [870.0, 626.0, 2.0, 941.0, 636.0, 2.0, 1012.0, 626.0, 2.0, 1012.0, 621.0, 1.0, 946.0, 631.0, 1.0, 904.0, 614.0, 2.0, 1011.0, 617.0, 1.0, 1087.0, 628.0, 1.0, 1138.0, 636.0, 2.0, 1209.0, 646.0, 2.0, 980.0, 648.0, 2.0, 1043.0, 651.0, 2.0, 1095.0, 646.0, 2.0, 1128.0, 626.0, 1.0, 1112.0, 622.0, 1.0, 1071.0, 620.0, 1.0], [870.0, 626.0, 2.0, 941.0, 636.0, 2.0, 1012.0, 626.0, 2.0, 1012.0, 621.0, 1.0, 946.0, 631.0, 1.0, 904.0, 614.0, 2.0, 1011.0, 617.0, 1.0, 1087.0, 628.0, 1.0, 1138.0, 636.0, 2.0, 1209.0, 646.0, 2.0, 980.0, 648.0, 2.0, 1043.0, 651.0, 2.0, 1095.0, 646.0, 2.0, 1128.0, 626.0, 1.0, 1112.0, 622.0, 1.0, 1071.0, 620.0, 1.0], [870.0, 626.0, 2.0, 941.0, 636.0, 2.0, 1012.0, 626.0, 2.0, 1012.0, 621.0, 1.0, 946.0, 631.0, 1.0, 904.0, 614.0, 2.0, 1011.0, 617.0, 1.0, 1087.0, 628.0, 1.0, 1138.0, 636.0, 2.0, 1209.0, 646.0, 2.0, 980.0, 648.0, 2.0, 1043.0, 651.0, 2.0, 1095.0, 646.0, 2.0, 1128.0, 626.0, 1.0, 1112.0, 622.0, 1.0, 1071.0, 620.0, 1.0], [870.0, 626.0, 2.0, 941.0, 636.0, 2.0, 1012.0, 626.0, 2.0, 1012.0, 621.0, 1.0, 946.0, 631.0, 1.0, 904.0, 614.0, 2.0, 1011.0, 617.0, 1.0, 1087.0, 628.0, 1.0, 1138.0, 636.0, 2.0, 1209.0, 646.0, 2.0, 980.0, 648.0, 2.0, 1043.0, 651.0, 2.0, 1095.0, 646.0, 2.0, 1128.0, 626.0, 1.0, 1112.0, 622.0, 1.0, 1071.0, 620.0, 1.0], [869.0, 622.0, 2.0, 950.0, 638.0, 2.0, 1011.0, 622.0, 2.0, 1012.0, 615.0, 1.0, 960.0, 627.0, 1.0, 907.0, 620.0, 2.0, 1011.0, 617.0, 1.0, 1092.0, 619.0, 1.0, 1146.0, 620.0, 2.0, 1208.0, 614.0, 2.0, 1041.0, 648.0, 2.0, 1039.0, 586.0, 2.0, 1121.0, 626.0, 2.0, 1145.0, 613.0, 1.0, 1115.0, 592.0, 2.0, 1098.0, 624.0, 1.0], [862.0, 616.0, 2.0, 950.0, 633.0, 2.0, 1011.0, 617.0, 2.0, 1026.0, 607.0, 1.0, 960.0, 633.0, 1.0, 908.0, 617.0, 1.0, 1012.0, 616.0, 1.0, 1078.0, 599.0, 1.0, 1122.0, 587.0, 2.0, 1180.0, 552.0, 2.0, 1028.0, 651.0, 2.0, 1013.0, 599.0, 2.0, 1092.0, 580.0, 2.0, 1134.0, 590.0, 1.0, 1122.0, 627.0, 1.0, 1127.0, 652.0, 2.0], [858.0, 612.0, 2.0, 947.0, 640.0, 2.0, 993.0, 611.0, 2.0, 996.0, 613.0, 1.0, 945.0, 632.0, 1.0, 911.0, 615.0, 1.0, 994.0, 612.0, 1.0, 1054.0, 566.0, 1.0, 1094.0, 535.0, 2.0, 1134.0, 484.0, 2.0, 1029.0, 644.0, 2.0, 1027.0, 602.0, 2.0, 1063.0, 530.0, 2.0, 1119.0, 539.0, 2.0, 1115.0, 602.0, 2.0, 1119.0, 640.0, 2.0], [878.0, 614.0, 2.0, 921.0, 640.0, 2.0, 973.0, 581.0, 2.0, 983.0, 593.0, 1.0, 960.0, 629.0, 1.0, 910.0, 616.0, 1.0, 979.0, 588.0, 1.0, 1046.0, 551.0, 1.0, 1090.0, 527.0, 2.0, 1149.0, 485.0, 2.0, 1031.0, 637.0, 2.0, 1040.0, 597.0, 2.0, 1056.0, 519.0, 2.0, 1107.0, 531.0, 2.0, 1115.0, 602.0, 2.0, 1119.0, 644.0, 2.0], [873.0, 617.0, 2.0, 910.0, 644.0, 2.0, 947.0, 550.0, 2.0, 964.0, 574.0, 1.0, 960.0, 638.0, 2.0, 912.0, 611.0, 2.0, 957.0, 563.0, 1.0, 1020.0, 546.0, 1.0, 1062.0, 535.0, 2.0, 1128.0, 506.0, 2.0, 1019.0, 644.0, 2.0, 1010.0, 598.0, 2.0, 1030.0, 524.0, 2.0, 1090.0, 552.0, 1.0, 1098.0, 602.0, 2.0, 1111.0, 644.0, 2.0]]\n",
      "[[196 132   0 ... 214  75   0]\n",
      " [196 132   0 ... 214  75   0]\n",
      " [194 133   0 ... 216  90   0]\n",
      " ...\n",
      " [180 128   0 ... 236 134   0]\n",
      " [185 129   0 ... 236 135   0]\n",
      " [184 130   0 ... 234 135   0]]\n"
     ]
    }
   ],
   "source": [
    "print(true_data[0])\n",
    "\n",
    "data = (255*(true_data[0] - np.min(true_data[0]))/np.ptp(true_data[0])).astype(int)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, data in enumerate(true_data):\n",
    "    data = (255*(data - np.min(data))/np.ptp(data)).astype(int)\n",
    "    if len(data) < 30:\n",
    "        tmp_list = [[0 for w in range(48)] for h in range(30-len(data))]\n",
    "        data += tmp_list\n",
    "        true_data[index]=data\n",
    "    else:\n",
    "        true_data[index] = data[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, data in enumerate(false_data):\n",
    "    if len(data) < 30:\n",
    "        tmp_list = [[0 for w in range(48)] for h in range(30-len(data))]\n",
    "        data += tmp_list\n",
    "        false_data[index]=data\n",
    "    else:\n",
    "        false_data[index] = data[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "true_np = np.array(true_data, dtype=np.float32)\n",
    "false_np = np.array(false_data, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(198335, 30, 48)\n",
      "(3831, 30, 48)\n"
     ]
    }
   ],
   "source": [
    "print(false_np.shape)\n",
    "print(true_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [(3*i)-1 for i in range(1, 17)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_np = np.delete(false_np, index, 2)\n",
    "true_np = np.delete(true_np, index, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_np = np.repeat(true_np, 30, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114930, 30, 32)\n"
     ]
    }
   ],
   "source": [
    "print(true_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([1 for w in range(len(true_np))])\n",
    "y_false = np.array([0 for w in range(len(false_np))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = np.concatenate((false_np, true_np), axis=0)\n",
    "data_y = np.concatenate((y_false, y_true), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(313265, 30, 32)\n",
      "(313265,)\n"
     ]
    }
   ],
   "source": [
    "print(data_x.shape)\n",
    "print(data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(data_x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     0      1      2 ... 313262 313263 313264]\n"
     ]
    }
   ],
   "source": [
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[143741 311273 125947 ... 219913 229540 109555]\n"
     ]
    }
   ],
   "source": [
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = data_x[idx]\n",
    "data_y = data_y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_frac = 0.8\n",
    "\n",
    "## split data into training, validation, and test data (features and labels, x and y)\n",
    "split_idx = int(len(data_x)*0.8)\n",
    "train_x, remaining_x = data_x[:split_idx], data_x[split_idx:]\n",
    "train_y, remaining_y = data_y[:split_idx], data_y[split_idx:]\n",
    "\n",
    "test_idx = int(len(remaining_x)*0.5)\n",
    "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
    "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_data, 'train_mul.pt')\n",
    "torch.save(test_data, 'test_mul.pt')\n",
    "torch.save(valid_data, 'valid_mul.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198335"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(false_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(true_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(313265, 30, 32)\n",
      "(313265, 30, 32)\n",
      "(313265, 30, 32)\n",
      "(313265, 30, 32)\n",
      "(313265, 30, 32)\n",
      "(313265, 30, 32)\n",
      "(313265, 30, 32)\n",
      "(313265, 30, 32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m np_arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(arr, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      4\u001b[0m np_arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdelete(np_arr, index, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m((\u001b[43mdata_x\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp_arr\u001b[49m)\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for arr in true_data:\n",
    "    np_arr = np.array(arr, dtype=np.float32)\n",
    "    \n",
    "    np_arr = np.delete(np_arr, index, 1)\n",
    "    \n",
    "    print((data_x == np_arr).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_list = [[0 for i in range(20)] for j in range (30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 -1  0  1  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 -1  0  1  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [-1  0  1  0  1  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 -1  0  1  0  1  0  0  0  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 -1  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 -1  0  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 -1  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 -1  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "sub_mat = np.zeros((32, 20), dtype=int)\n",
    "index_a = [9, 8, 8, 14, 11, 8, 6, 6, 4, 1]\n",
    "index_b = [8, 14, 11, 15, 10, 6, 4, 1, 5, 0]\n",
    "\n",
    "for i, (a, b) in enumerate(zip(index_a, index_b)):\n",
    "    sub_mat[a*2, i*2] = 1\n",
    "    sub_mat[b*2, i*2] = -1\n",
    "\n",
    "    sub_mat[a*2+1, i*2 + 1] = 1\n",
    "    sub_mat[b*2+1, i*2 + 1] = -1\n",
    "\n",
    "\n",
    "print(sub_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313265/313265 [00:12<00:00, 25519.70it/s]\n"
     ]
    }
   ],
   "source": [
    "num_list = list()\n",
    "\n",
    "for data in tqdm(data_x):\n",
    "    \n",
    "    np_arr = data@sub_mat\n",
    "    \n",
    "    if(np.ptp(np_arr) != 0):\n",
    "        np_arr = (np_arr - np.min(np_arr))/np.ptp(np_arr)\n",
    "        \n",
    "    #print(np_arr.shape)\n",
    "    \n",
    "    num_list.append(np_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313265, 30, 20)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_np = np.array(num_list, dtype=np.float32)\n",
    "new_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_frac = 0.8\n",
    "\n",
    "## split data into training, validation, and test data (features and labels, x and y)\n",
    "split_idx = int(len(data_x)*0.8)\n",
    "train_x, remaining_x = new_np[:split_idx], new_np[split_idx:]\n",
    "train_y, remaining_y = data_y[:split_idx], data_y[split_idx:]\n",
    "\n",
    "test_idx = int(len(remaining_x)*0.5)\n",
    "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
    "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "torch.save(train_data, 'train_nomal.pt')\n",
    "torch.save(test_data, 'test_nomal.pt')\n",
    "torch.save(valid_data, 'valid_nomal.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250612, 30, 20)\n",
      "(250612,)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6158192  0.36158192 1.         0.40112993 0.47740114 0.15536723\n",
      "  0.33050847 0.47457626 0.5423729  0.7627119  0.5706215  0.\n",
      "  0.48022598 0.45480227 0.69491524 0.2881356  0.5536723  0.37853107\n",
      "  0.84463274 0.31920904]\n",
      " [0.700565   0.41525424 0.87288135 0.36158192 0.7259887  0.22881356\n",
      "  0.46892655 0.4180791  0.519774   0.43502825 0.81920904 0.12146892\n",
      "  0.6129944  0.37288135 0.28248587 0.47740114 0.75706214 0.34463277\n",
      "  0.5423729  0.3983051 ]\n",
      " [0.759887   0.4915254  0.8163842  0.44915253 0.43502825 0.3022599\n",
      "  0.4463277  0.46327683 0.4858757  0.45762712 0.88135594 0.26836157\n",
      "  0.46892655 0.460452   0.25706214 0.5084746  0.7033898  0.4180791\n",
      "  0.75706214 0.40112993]\n",
      " [0.69774014 0.5423729  0.7824859  0.48022598 0.52259886 0.36723164\n",
      "  0.49717513 0.5141243  0.51129943 0.50282484 0.9463277  0.41525424\n",
      "  0.5254237  0.45762712 0.38418078 0.53672314 0.7627119  0.5508475\n",
      "  0.720339   0.4435028 ]\n",
      " [0.6779661  0.5875706  0.7655367  0.5        0.55649716 0.39265537\n",
      "  0.50282484 0.5084746  0.52259886 0.5536723  0.9491525  0.5423729\n",
      "  0.6751412  0.37288135 0.36723164 0.38135594 0.7881356  0.5621469\n",
      "  0.83898306 0.5338983 ]\n",
      " [0.68079096 0.58474576 0.7542373  0.5141243  0.5451977  0.3418079\n",
      "  0.47740114 0.5141243  0.5677966  0.63559324 0.91525424 0.51129943\n",
      "  0.81073445 0.37853107 0.66101694 0.2881356  0.7627119  0.5706215\n",
      "  0.8615819  0.5338983 ]\n",
      " [0.7259887  0.55932206 0.77683616 0.57344633 0.4858757  0.38418078\n",
      "  0.4378531  0.5536723  0.6158192  0.65254235 0.94350284 0.4463277\n",
      "  0.8418079  0.4858757  0.75141245 0.4124294  0.84745765 0.58474576\n",
      "  0.78531075 0.51129943]\n",
      " [0.69491524 0.59322035 0.8220339  0.5621469  0.5282486  0.4124294\n",
      "  0.45480227 0.5536723  0.58474576 0.65536726 0.9858757  0.47457626\n",
      "  0.8870056  0.5084746  0.75141245 0.4124294  0.8248588  0.56497175\n",
      "  0.78531075 0.51129943]\n",
      " [0.69491524 0.59322035 0.8220339  0.5621469  0.5282486  0.4124294\n",
      "  0.45480227 0.5536723  0.58474576 0.65536726 0.9858757  0.47457626\n",
      "  0.8870056  0.5084746  0.779661   0.40677965 0.8248588  0.56497175\n",
      "  0.86723167 0.5254237 ]\n",
      " [0.69491524 0.59322035 0.8220339  0.5621469  0.5282486  0.4124294\n",
      "  0.45480227 0.5536723  0.58474576 0.65536726 0.9858757  0.47457626\n",
      "  0.8870056  0.5084746  0.779661   0.40677965 0.8248588  0.56497175\n",
      "  0.86723167 0.5254237 ]\n",
      " [0.69491524 0.59322035 0.8220339  0.5621469  0.5282486  0.4124294\n",
      "  0.45480227 0.5536723  0.58474576 0.65536726 0.9858757  0.47457626\n",
      "  0.8870056  0.5084746  0.779661   0.40677965 0.8248588  0.56497175\n",
      "  0.86723167 0.5254237 ]\n",
      " [0.69491524 0.59322035 0.8220339  0.5621469  0.5282486  0.4124294\n",
      "  0.45480227 0.5536723  0.58474576 0.65536726 0.9858757  0.47457626\n",
      "  0.8870056  0.5084746  0.779661   0.40677965 0.8248588  0.56497175\n",
      "  0.86723167 0.5254237 ]\n",
      " [0.69491524 0.59322035 0.8220339  0.5621469  0.5282486  0.4124294\n",
      "  0.45480227 0.5536723  0.58474576 0.65536726 0.9858757  0.47457626\n",
      "  0.8870056  0.5084746  0.779661   0.40677965 0.8248588  0.56497175\n",
      "  0.86723167 0.5254237 ]\n",
      " [0.69491524 0.59322035 0.8220339  0.5621469  0.5282486  0.4124294\n",
      "  0.45480227 0.5536723  0.58474576 0.65536726 0.9858757  0.47457626\n",
      "  0.8870056  0.5084746  0.779661   0.40677965 0.8248588  0.56497175\n",
      "  0.86723167 0.5254237 ]\n",
      " [0.69491524 0.59322035 0.8220339  0.5621469  0.5282486  0.4124294\n",
      "  0.45480227 0.5536723  0.58474576 0.65536726 0.9858757  0.47457626\n",
      "  0.8870056  0.5084746  0.779661   0.40677965 0.8248588  0.56497175\n",
      "  0.86723167 0.5254237 ]\n",
      " [0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706 ]\n",
      " [0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706 ]\n",
      " [0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706 ]\n",
      " [0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706 ]\n",
      " [0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706 ]\n",
      " [0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706 ]\n",
      " [0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706 ]\n",
      " [0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706 ]\n",
      " [0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706 ]\n",
      " [0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706 ]\n",
      " [0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706 ]\n",
      " [0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706 ]\n",
      " [0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706 ]\n",
      " [0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706 ]\n",
      " [0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706  0.5875706\n",
      "  0.5875706  0.5875706 ]]\n"
     ]
    }
   ],
   "source": [
    "print(new_np[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4966443 , 0.2818792 , 0.82214767, 0.62416106, 0.7684564 ,\n",
       "        0.62416106, 0.5872483 , 0.76510066, 0.6409396 , 0.7483221 ,\n",
       "        0.62416106, 0.05033557, 0.5503356 , 0.21140939, 0.5671141 ,\n",
       "        0.24496645, 0.53355706, 0.19127516, 0.5167785 , 0.21140939],\n",
       "       [0.45973155, 0.31879196, 0.82214767, 0.46308726, 0.7852349 ,\n",
       "        0.5       , 0.7852349 , 0.6577181 , 0.7852349 , 0.6208054 ,\n",
       "        0.53355706, 0.06711409, 0.62416106, 0.21140939, 0.60738254,\n",
       "        0.24832214, 0.53355706, 0.15771812, 0.5503356 , 0.19127516],\n",
       "       [0.33892617, 0.44295302, 0.60402685, 0.24496645, 0.5872483 ,\n",
       "        0.31879196, 0.67785233, 0.37248322, 0.6409396 , 0.37248322,\n",
       "        0.22818792, 0.1375839 , 0.7281879 , 0.19463088, 0.7114094 ,\n",
       "        0.24832214, 0.5704698 , 0.22818792, 0.60402685, 0.24496645],\n",
       "       [0.32214764, 0.5402685 , 0.5067114 , 0.25503355, 0.4966443 ,\n",
       "        0.33557048, 0.6107383 , 0.38255033, 0.5771812 , 0.40604028,\n",
       "        0.08389262, 0.4161074 , 0.9194631 , 0.31208053, 0.852349  ,\n",
       "        0.32550335, 0.4966443 , 0.24496645, 0.5167785 , 0.29865772],\n",
       "       [0.32550335, 0.5067114 , 0.66442955, 0.31543624, 0.6442953 ,\n",
       "        0.37248322, 0.7147651 , 0.40268457, 0.68791944, 0.4362416 ,\n",
       "        0.15100671, 0.33557048, 1.        , 0.55369127, 0.9295302 ,\n",
       "        0.6577181 , 0.3456376 , 0.39261746, 0.3489933 , 0.32214764],\n",
       "       [0.43288592, 0.6510067 , 0.6006711 , 0.31208053, 0.5302013 ,\n",
       "        0.39261746, 0.67785233, 0.3590604 , 0.6912752 , 0.40604028,\n",
       "        0.08389262, 0.5067114 , 0.97651005, 0.39261746, 0.9194631 ,\n",
       "        0.5201342 , 0.30201343, 0.4295302 , 0.3456376 , 0.39261746],\n",
       "       [0.33892617, 0.61744964, 0.5167785 , 0.2818792 , 0.47651008,\n",
       "        0.37919462, 0.6006711 , 0.39261746, 0.6006711 , 0.40604028,\n",
       "        0.0738255 , 0.5167785 , 0.738255  , 0.18456376, 0.6677852 ,\n",
       "        0.295302  , 0.26845637, 0.61409396, 0.33892617, 0.5604027 ],\n",
       "       [0.32214764, 0.60402685, 0.4899329 , 0.26510066, 0.44966444,\n",
       "        0.36241612, 0.6006711 , 0.40939596, 0.5872483 , 0.44966444,\n",
       "        0.08724833, 0.4899329 , 0.72483224, 0.16778524, 0.8087248 ,\n",
       "        0.37919462, 0.2818792 , 0.6577181 , 0.22818792, 0.5302013 ],\n",
       "       [0.32550335, 0.6275168 , 0.4899329 , 0.26845637, 0.47315437,\n",
       "        0.32550335, 0.6409396 , 0.42281878, 0.6442953 , 0.43288592,\n",
       "        0.0704698 , 0.47651008, 0.79530203, 0.2147651 , 0.7281879 ,\n",
       "        0.295302  , 0.25503355, 0.6409396 , 0.32214764, 0.60402685],\n",
       "       [0.32550335, 0.63422817, 0.51342285, 0.2785235 , 0.5503356 ,\n",
       "        0.4261745 , 0.761745  , 0.52684563, 0.7114094 , 0.46308726,\n",
       "        0.13087249, 0.5402685 , 0.83557045, 0.31208053, 0.83557045,\n",
       "        0.41275167, 0.30201343, 0.62416106, 0.31543624, 0.6006711 ],\n",
       "       [0.38926175, 0.74496645, 0.48657718, 0.31543624, 0.5       ,\n",
       "        0.46644294, 0.761745  , 0.5637584 , 0.6979866 , 0.48657718,\n",
       "        0.09060403, 0.6275168 , 0.8489933 , 0.33892617, 0.8489933 ,\n",
       "        0.46308726, 0.2885906 , 0.5872483 , 0.32550335, 0.52348995],\n",
       "       [0.4261745 , 0.79530203, 0.4899329 , 0.30536914, 0.52684563,\n",
       "        0.51342285, 0.7718121 , 0.62416106, 0.52684563, 0.4899329 ,\n",
       "        0.10738255, 0.68791944, 0.8322148 , 0.31543624, 0.88255036,\n",
       "        0.40268457, 0.30536914, 0.59731543, 0.26510066, 0.5604027 ],\n",
       "       [0.39932886, 0.77516776, 0.48657718, 0.29865772, 0.53691274,\n",
       "        0.51342285, 0.77516776, 0.6375839 , 0.66442955, 0.48657718,\n",
       "        0.09731544, 0.66442955, 0.86577183, 0.30872482, 0.91610736,\n",
       "        0.40939596, 0.27181208, 0.6006711 , 0.23489933, 0.5872483 ],\n",
       "       [0.39932886, 0.77516776, 0.48657718, 0.2852349 , 0.52348995,\n",
       "        0.5       , 0.77516776, 0.6375839 , 0.68791944, 0.45973155,\n",
       "        0.09731544, 0.6510067 , 0.86577183, 0.30872482, 0.91610736,\n",
       "        0.40939596, 0.27181208, 0.6006711 , 0.24832214, 0.5771812 ],\n",
       "       [0.40939596, 0.73489934, 0.47651008, 0.29865772, 0.51342285,\n",
       "        0.47651008, 0.738255  , 0.5402685 , 0.6610738 , 0.4362416 ,\n",
       "        0.08724833, 0.6006711 , 0.8389262 , 0.26174498, 0.8489933 ,\n",
       "        0.39932886, 0.24832214, 0.6510067 , 0.23825504, 0.5872483 ],\n",
       "       [0.3489933 , 0.68791944, 0.52348995, 0.2852349 , 0.5       ,\n",
       "        0.40939596, 0.6375839 , 0.4362416 , 0.647651  , 0.39932886,\n",
       "        0.10738255, 0.52348995, 0.7516779 , 0.2080537 , 0.8020134 ,\n",
       "        0.37248322, 0.27181208, 0.6510067 , 0.23154363, 0.5637584 ],\n",
       "       [0.32214764, 0.647651  , 0.5738255 , 0.2852349 , 0.53691274,\n",
       "        0.37248322, 0.62416106, 0.39932886, 0.6510067 , 0.38590604,\n",
       "        0.12080537, 0.47651008, 0.8020134 , 0.2181208 , 0.90268457,\n",
       "        0.48322147, 0.25838926, 0.6510067 , 0.18120806, 0.44966444],\n",
       "       [0.30872482, 0.5738255 , 0.6375839 , 0.2818792 , 0.61409396,\n",
       "        0.37248322, 0.7013423 , 0.48657718, 0.67449665, 0.45973155,\n",
       "        0.19798657, 0.33221477, 0.86577183, 0.26174498, 0.86577183,\n",
       "        0.52684563, 0.26845637, 0.647651  , 0.30872482, 0.44630873],\n",
       "       [0.33557048, 0.52684563, 0.6577181 , 0.23825504, 0.4295302 ,\n",
       "        0.44966444, 0.5671141 , 0.6375839 , 0.69463086, 0.4966443 ,\n",
       "        0.22818792, 0.23825504, 0.9261745 , 0.2885906 , 0.87583894,\n",
       "        0.6577181 , 0.24832214, 0.66442955, 0.23825504, 0.3557047 ],\n",
       "       [0.3489933 , 0.47651008, 0.72483224, 0.25838926, 0.4161074 ,\n",
       "        0.39597315, 0.47651008, 0.52684563, 0.67785233, 0.4295302 ,\n",
       "        0.31543624, 0.15771812, 0.91610736, 0.2852349 , 0.7986577 ,\n",
       "        0.48657718, 0.23825504, 0.5771812 , 0.3657718 , 0.4261745 ],\n",
       "       [0.3557047 , 0.46308726, 0.5872483 , 0.26174498, 0.38255033,\n",
       "        0.31879196, 0.53691274, 0.37248322, 0.67449665, 0.36241612,\n",
       "        0.23825504, 0.19463088, 0.8590604 , 0.22483222, 0.761745  ,\n",
       "        0.45302013, 0.2785235 , 0.36241612, 0.5671141 , 0.15771812],\n",
       "       [0.39261746, 0.39261746, 0.5402685 , 0.22818792, 0.39261746,\n",
       "        0.34228188, 0.5704698 , 0.3456376 , 0.47315437, 0.39261746,\n",
       "        0.34228188, 0.06711409, 0.7181208 , 0.18120806, 0.7013423 ,\n",
       "        0.21140939, 0.5402685 , 0.22818792, 0.52348995, 0.26174498],\n",
       "       [0.45637584, 0.32885906, 0.7852349 , 0.38926175, 0.7684564 ,\n",
       "        0.40604028, 0.7986577 , 0.557047  , 0.7986577 , 0.55369127,\n",
       "        0.52348995, 0.        , 0.6375839 , 0.19463088, 0.6208054 ,\n",
       "        0.22818792, 0.55369127, 0.2147651 , 0.53691274, 0.24496645],\n",
       "       [0.4899329 , 0.2785235 , 0.82885903, 0.5872483 , 0.7986577 ,\n",
       "        0.60402685, 0.5872483 , 0.76510066, 0.61744964, 0.76510066,\n",
       "        0.5872483 , 0.03355705, 0.5872483 , 0.19463088, 0.5872483 ,\n",
       "        0.24496645, 0.55369127, 0.2147651 , 0.5201342 , 0.21140939],\n",
       "       [0.53691274, 0.30536914, 0.81543624, 0.40939596, 0.7986577 ,\n",
       "        0.47986576, 0.7281879 , 0.7114094 , 0.7281879 , 0.6577181 ,\n",
       "        0.5872483 , 0.02348993, 0.60402685, 0.20134228, 0.5872483 ,\n",
       "        0.25167784, 0.5503356 , 0.19798657, 0.5503356 , 0.18456376],\n",
       "       [0.5       , 0.30536914, 0.5704698 , 0.18120806, 0.5704698 ,\n",
       "        0.27181208, 0.74496645, 0.53691274, 0.6912752 , 0.4966443 ,\n",
       "        0.55369127, 0.04026845, 0.60402685, 0.18456376, 0.5872483 ,\n",
       "        0.2181208 , 0.5503356 , 0.18120806, 0.53355706, 0.20134228],\n",
       "       [0.39261746, 0.37583894, 0.48322147, 0.25167784, 0.46308726,\n",
       "        0.2885906 , 0.6912752 , 0.44630873, 0.67785233, 0.44630873,\n",
       "        0.44630873, 0.04026845, 0.62416106, 0.18456376, 0.5872483 ,\n",
       "        0.2181208 , 0.5872483 , 0.19798657, 0.5704698 , 0.20134228],\n",
       "       [0.31543624, 0.48322147, 0.3456376 , 0.3456376 , 0.32885906,\n",
       "        0.4194631 , 0.5704698 , 0.37583894, 0.51342285, 0.36241612,\n",
       "        0.23825504, 0.13422818, 0.66442955, 0.13422818, 0.647651  ,\n",
       "        0.17785235, 0.6006711 , 0.22483222, 0.61744964, 0.25503355],\n",
       "       [0.2852349 , 0.557047  , 0.32885906, 0.37583894, 0.29865772,\n",
       "        0.46644294, 0.51342285, 0.3456376 , 0.4966443 , 0.3456376 ,\n",
       "        0.19463088, 0.19463088, 0.6610738 , 0.11744966, 0.647651  ,\n",
       "        0.147651  , 0.61744964, 0.22483222, 0.6308725 , 0.25503355],\n",
       "       [0.31543624, 0.45302013, 0.38926175, 0.31543624, 0.3456376 ,\n",
       "        0.38926175, 0.557047  , 0.37583894, 0.52684563, 0.36241612,\n",
       "        0.2852349 , 0.11744966, 0.647651  , 0.13422818, 0.647651  ,\n",
       "        0.18120806, 0.6006711 , 0.22483222, 0.61744964, 0.23825504]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_np[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
